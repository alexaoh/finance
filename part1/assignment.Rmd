---
title: "Assignment"
subtitle: "Option Pricing and Risk - Financial Statistics"
author: "Alexander J Ohrt"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 3
    theme: readable
    highlight: textmate
    number_sections: true
  pdf_document:
    fig_caption: true
    number_sections: true
    toc: false
editor_options: 
  chunk_output_type: console
geometry:
  margin = 2.2cm
urlcolor: blue
linkcolor: black
---

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = F, warning = F, fig.width = 10, comment = "#>", size = "scriptsize")
setwd("/home/ajo/gitRepos/finance/part1")
library(ggplot2)
library(tidyverse)
library(reshape2)
```

# Problem A - Euler-Maruyama Method

First we implement a discretization for the Black-Scholes-Merton (BSM) price dynamics with the given parameter set, with $n = 250$ steps. We generate $M_1 = 10$, $M_2 = 100$, $M_3 = 1000$, $M_4 = 10000$ and $M_5 = 100000$ paths. The paths are plotted in separate figures for the three first cases. 

```{r}
set.seed(061999)
s0 <- 12
T1 <- 1
mu <- 0.03
sigma <- 0.17
n <-  250
t <- seq(0, T1, length.out = n+1) # n steps means n+1 points in this vector. 
h <- t[2] - t[1] # h = T1/n gives the same result. 
M1 <- 10
M2 <- 100
M3 <- 1000
M4 <- 10000
M5 <- 100000
```

The price dynamics are implemented using the function shown below, which is used to calculate each path. Notice that, since the Wiener process has the distribution $W_t \sim N(0,t), \forall t \in (0, t]$, we can think of such a process as a cumulative summation of normally distributed random variables. Thus, on our uniform discrete grid 

$$
0 = t_0 < \ldots < t_n = T,
$$ 
we can simulate the following relation 

$$
X(t_0) = 0, \hspace{0.3em} X(t_1) \sim N(0,t_1) = N(0, t_0+h), \ldots, \hspace{0.3em} X(t_n) \sim N(t_0 + nh) = X(t_1) + \ldots + X(t_{n-1}), 
$$
where $X$ represents the Brownian motion, $n$ is the number of steps in the discretization and $h = \frac{T}{n}$ is the step size. 

VIL HAN HA EULER-MARUYAMA HER OG IKKE DENNE FORMELEN? DET ER ENKELT Å BYTTE UT, MEN MÅ SPØRRE (FOR EM ER IMPLEMENTERT LENGER NEDE UANSETT!)

```{r, echo = T}
# Price path stochastic process. 
price.path <- function(s0, t, mu, sigma){
  Wt <- rnorm(n = length(t), sd = sqrt(t[2]-t[1])) # Draw length(t) normally distributed variables with mean 0 and standard deviation h. 
  W2 <- cumsum(Wt) # Step size is constant, grid is uniform. We calculate the cumulative sum of the standard normal draw to simulate the Wiener process, which is N(0,t) at time t, i.e. the variance increases when the process is run further and further away from t = 0. Notice that we also multiply by the (uniform) stepsize used on the (uniform) grid, in order to transform the N(0,1) values to N(0,t). 
  s0*exp(mu*t)*exp(sigma*W2-sigma^2/2*t)
}

# VIL HAN EGENTLIG HA EULER-MARUYAMA HER TIL Å LAGE HVER PATH I STEDET!? ELLER ER DETTE OK? 
```

```{r}
# Generate the price paths for all the given number of paths. 
M1.paths <- matrix(rep(NA, length.out = M1*(n+1)), nrow = M1)
for (i in 1:M1){
  M1.paths[i,] <- price.path(s0 = s0, t = t, mu = mu, sigma = sigma)
}

M2.paths <- matrix(rep(NA, length.out = M2*(n+1)), nrow = M2)
for (i in 1:M2){
  M2.paths[i,] <- price.path(s0, t, mu, sigma)
}

M3.paths <- matrix(rep(NA, length.out = M3*(n+1)), nrow = M3)
for (i in 1:M3){
  M3.paths[i,] <- price.path(s0, t, mu, sigma)
}

M4.paths <- matrix(rep(NA, length.out = M4*(n+1)), nrow = M4)
for (i in 1:M4){
  M4.paths[i,] <- price.path(s0, t, mu, sigma)
}

M5.paths <- matrix(rep(NA, length.out = M5*(n+1)), nrow = M5)
for (i in 1:M5){
  M5.paths[i,] <- price.path(s0, t, mu, sigma)
}
```

```{r}
mean.value <- s0*exp(mu*t)
matplot(t(M1.paths), type = "l", main = paste0(M1," paths"), xlab = "t in years", ylab = "S", xaxt = "n", ylim = c(8, 20))
lines(mean.value) # Drift / "mean value".
axis(1, at=seq(0,n, by = 10), labels = seq(0,1,length.out = n/10+1))

matplot(t(M2.paths), type = "l", main = paste0(M2," paths"), xlab = "t in years", ylab = "S", xaxt = "n", ylim = c(8, 20))
#lines(apply(M2.paths, 2, mean), cex = 2)
lines(mean.value) # Drift / "mean value".
axis(1, at=seq(0,n, by = 10), labels = seq(0,1,length.out = n/10+1))

matplot(t(M3.paths), type = "l", main = paste0(M3," paths"), xlab = "t in years", ylab = "S", xaxt = "n", ylim = c(8, 20))
lines(mean.value) # Drift / "mean value".
axis(1, at=seq(0,n, by = 10), labels = seq(0,1,length.out = n/10+1))
```

The Monte Carlo estimator for $\hat{S}_T$ is calculated separately for each of the values of $M_i, \hspace{0.5em} i \in \{1,2,3,4,5\}$. The 95\% confidence interval (CI) is provided for each estimator. A comparison between these estimators and the analytical solution of $\mathbb{E}(S_T)$ is done and differences are explained. 

The Monte Carlo estimator for $\hat{S}_T$ is simply calculated by averaging the values of all the different BSM price paths plotted above at time $T = 1$. The $(1-\alpha)\% = (1-0.05)\% = 95\%$ CIs are calculated by finding the standard error of the values of all the different BSM price paths at time $T$ and using the approximation given by 

$$
CI_{\alpha} = \left(\hat{S}_T - z_{\alpha/2}\frac{se_{\hat{S}_T}}{\sqrt{M}}, \hat{S}_T + z_{\alpha/2}\frac{se_{\hat{S}_T}}{\sqrt{M}}\right), 
$$
where $se_{\hat{S}_T}$ is the aforementioned standard error,  $z_{\alpha/2}$ is the $1-\alpha$ quantile of the standard normal distribution and $M$ is the number of price paths simulated. This is an asymptotically valid $1-\alpha$ CI, which means it becomes closer to the exact analytic value when $M$ is increased. 

```{r}
# Calculate the Monte-Carlo estimator of $\hat{S}_T$ for each of the values of $M_i$.
hat_ST <- function(M, n){
  mean(M[,n+1]) # Calculate mean over last value of all M_i paths. 
}
# This simply calculates the average over the last value of all the different paths. 

CI_ST <- function(M, n){
  s <- sd(M[,n+1]) # Calculate sample standard deviation over last value of all M_i paths. 
  m <- hat_ST(M, n) # Calculate mean.
  ste <- qnorm(0.975)*s/sqrt(dim(M)[[1]])
  return(list(l = m - ste, u = m + ste))
}
```

```{r}
M1.hat <- hat_ST(M1.paths, n) 
CI1 <- CI_ST(M1.paths, n)
M2.hat <- hat_ST(M2.paths, n) 
CI2 <- CI_ST(M2.paths, n)
M3.hat <- hat_ST(M3.paths, n) 
CI3 <- CI_ST(M3.paths, n)
M4.hat <- hat_ST(M4.paths, n) 
CI4 <- CI_ST(M4.paths, n)
M5.hat <- hat_ST(M5.paths, n) 
CI5 <- CI_ST(M5.paths, n)

col1 <- rbind(M1.hat, CI1$l, CI1$u)
col2 <- rbind(M2.hat, CI2$l, CI2$u)
col3 <- rbind(M3.hat, CI3$l, CI3$u)
col4 <- rbind(M4.hat, CI4$l, CI4$u)
col5 <- rbind(M5.hat, CI5$l, CI5$u)

hats <- cbind(col1, col2, col3, col4, col5)
colnames(hats) <- c("M1 = 10", "M2 = 100", "M3 = 1000", "M4 = 10000", "M5 = 100000") 
rownames(hats) <- c("Est.", "Lower CI", "Upper CI")
knitr::kable(hats, caption = "Monte Carlo Estimation for S_T, varying M")
```

Now, what is the analytical solution for $\mathbb{E}(S_T)$? We know that the process of the risky asset in $t \in [0,T]$ is distributed as 

$$
S_t \sim \mathcal{L}N(\mu^{*}, \sigma^{*2}), 
$$

where $\mathbb{E}(S_T) = \mu^{*}$. In addition, we know that, when $W_t \sim N(0,t)$, it follows that 

$$
X_t \sim N(\ln S_0 - \left(\frac{\sigma^2}{2} - \mu\right)t, \sigma^2t) = N(\mu_{X_t}, \sigma^2_{X_t}), 
$$
where $S_t = e^{X_t}$. Finally, we know that the expected value of the log-normally distributed variable $S_t$ is $\exp{\left(\mu_{X_t} + \frac{\sigma^2_{X_t}}{2}\right)}$. This means that the analytical solution for $\mathbb{E}(S_T)$ is 

$$
\mu^* = \exp{\left(\mu_{X_t} + \frac{\sigma^2_{X_t}}{2}\right)} = \exp{\left(\ln S_0 -\left(\frac{\sigma^2}{2} - \mu\right)t + \frac{\sigma^2t}{2}\right)} = S_0 e^{\mu t},
$$
which in this case has the numerical value

```{r}
mean.value[length(mean.value)] # Drift / "mean value".
```

From the results above we can clearly see that the MC estimations move closer and closer to the analytical solution when the number of paths $M$ is increased. For $M_5$ the estimation is precise to the first 3 decimals, which I would regard as a very good estimation. We also see that the CI's clearly change with the increase of $M$; the lower value of the CI's increase with $M$ and the upper value of the CI's decrease with $M$, meaning that the $95\%$ CI's become narrower when the number of paths increase. This is what we expect from the MC theory, since the estimators are unbiased and, as stated by the strong Law of Large Numbers, the sample average converges a.s. to the true expected value. 

Now we fix the number of paths $M^* = 1000$ and vary the values of $n$, i.e. the number of steps, while repeating the discussion done above. 

```{r}
M.star <- 1000
n1 <- 12
n2 <- 24
n3 <- 250
n4 <- 1000
```

```{r}
# Find new paths. 
n1.paths <- matrix(rep(NA, length.out = M.star*(n1+1)), nrow = M.star)
for (i in 1:M.star){
  t1 <- seq(0, T1, length.out = n1+1) # n steps means n+1 points in this vector. 
  n1.paths[i,] <- price.path(s0, t1, mu, sigma)
}

n2.paths <- matrix(rep(NA, length.out = M.star*(n2+1)), nrow = M.star)
for (i in 1:M.star){
  t2 <- seq(0, T1, length.out = n2+1) # n steps means n+1 points in this vector. 
  n2.paths[i,] <- price.path(s0, t2, mu, sigma)
}

n3.paths <- matrix(rep(NA, length.out = M.star*(n3+1)), nrow = M.star)
for (i in 1:M.star){
  t3 <- seq(0, T1, length.out = n3+1) # n steps means n+1 points in this vector. 
  n3.paths[i,] <- price.path(s0, t3, mu, sigma)
}

n4.paths <- matrix(rep(NA, length.out = M.star*(n4+1)), nrow = M.star)
for (i in 1:M.star){
  t4 <- seq(0, T1, length.out = n4+1) # n steps means n+1 points in this vector. 
  n4.paths[i,] <- price.path(s0, t4, mu, sigma)
}
```

```{r, eval = F}
# Burde nok helst unngå den transponerte, heller definere matrisen omvendt.
matplot(t(n1.paths), type = "l")
matplot(t(n2.paths), type = "l")
matplot(t(n3.paths), type = "l")
matplot(t(n4.paths), type = "l")
```

```{r}
n1.hat <- hat_ST(n1.paths, n1) 
CI1 <- CI_ST(n1.paths, n1)
n2.hat <- hat_ST(n2.paths, n2) 
CI2 <- CI_ST(n2.paths, n2)
n3.hat <- hat_ST(n3.paths, n3) 
CI3 <- CI_ST(n3.paths, n3)
n4.hat <- hat_ST(n4.paths, n4) 
CI4 <- CI_ST(n4.paths, n4)

col1 <- rbind(n1.hat, CI1$l, CI1$u)
col2 <- rbind(n2.hat, CI2$l, CI2$u)
col3 <- rbind(n3.hat, CI3$l, CI3$u)
col4 <- rbind(n4.hat, CI4$l, CI4$u)

hats <- cbind(col1, col2, col3, col4)
colnames(hats) <- c("n1 = 12", "n2 = 24", "n3 = 250", "n4 = 1000")
rownames(hats) <- c("Est.", "Lower CI", "Upper CI")
knitr::kable(hats, caption = "Monte Carlo Estimation for S_T, varying n")
```


We can make several similar observations in this case; 

Notice however that is is the number of paths $M$, and not the number of discretization points $n$, that yields dramatic differences when the value is increased. In other words, the estimates move closer to the true value when $n$ is increased while $M$ is fixed, but the changes seem to be more dramatic when $n$ is fixed and $M$ is increased. It is however important to notice that, in our experiment, $n$ is only changed across three orders of magnitude, while $M$ is changed across five orders of magnitude, which might lead to a somewhat biased observation or discussion. 

# Problem B - Option Pricing I

```{r}
set.seed(061999)
s0 <- 24
T1 <- 1.5
r <- 0.02
sigma <- 0.22
K <- 23.5
```


```{r}
# BSM pricing formula for European call option, 
# to calculate the fair price at t = 0 in closed form.
BSM <- function(s0, T1, r, sigma, K){
  d1 <- (log(s0/K)+(r+sigma^2/2)*T1)/(sigma*sqrt(T1))
  d2 <- d1 - sigma*sqrt(T1)
  s0*pnorm(d1) - exp(-r*T1)*K*pnorm(d2)  
}
```

We calculate the price of the given Call option (parameters are given in code block above) with the Black-Scholes-Merton formula.

```{r}
(BSM.price <- BSM(s0, T1, r, sigma, K))
```

As we can see, the price is approximately equal to `r round(BSM.price, 2)`, when rounded to 2 decimals. 

We implement a Monte Carlo estimator for this option price by simulating paths with the Euler-Maruyama method for given steps and paths. 

Notice that for the path-independent options, like standard European call and put options, it is not needed to save the price path as is done below. This is done to keep the function as general as possible, in order to re-use it for the rest of the assignment. THIS COULD EASILY BE CHANGED IN THIS CASE IF TOO SLOW! (simply overwriting the previous value in the loop in every iteration).

```{r}
# Monte Carlo estimator for Euler-Maruyama. 
# This is for a Call option still (almost general) (slide 28)
MC <- function(M, n, r, s0, mu, h, sigma, T1, payoff.profile, set.S, ...){
  C.values <- rep(NA, length.out = M) # Initiate vector for saving payoffs per path. 
  for (i in 1:M){ # Initiate loop for M path.
    Z <- rnorm(n+1) # Generate n random variables standard normally. 
    S.values <- rep(NA, length.out = n+1) # Initiate vector for saving price path. 
    S.values[1] <- s0 # Initiate starting price at time t = 0. 
    for (j in 2:(n+1)){ # Loop for Euler-Maruyama - recursively estimate price path. 
      S.values[j] <- S.values[j-1] + mu*S.values[j-1]*h + sigma*S.values[j-1]*sqrt(h)*Z[j-1]
    }
    S <- set.S(S.values) # Set expected price used in payoff-profile. 
    # Generality is kept using a helper function set.S.
    C.values[i] <- payoff.profile(S, K) # Calculate payoff for the path and save in C.values.
  }
  exp(-r*T1)*mean(C.values) # Return discounted average payoff. This is the MC estimator. 
}
```

```{r}
# Definition of helper functions to feed into MC estimator code above. 
Call.profile <- function(S, K){
  max(0, S-K)
}

# Feed the function into the MC estimator in order to calculate estimate for Call option. 
Call.set.S <- function(S.values){
  S.values[length(S.values)] # The Call option uses the last value in the list. 
}
```

Assuming that $\mu = r$. 

```{r}
M.list <- c(10, 100, 1000, 10000, 100000)
n.list <- c(10, 100, 1000)
# Simulate paths with the MC estimator and Euler-Maruyama. 
combinations <- matrix(rep(NA, length.out = length(M.list)*length(n.list)), nrow = length(M.list))

for (i in 1:length(M.list)){
  for (j in 1:length(n.list)){
    h <- T1/n.list[j]
    combinations[i, j] <- MC(M = M.list[i], n = n.list[j], r = r, s0 = s0, mu = r, h = h, 
                             sigma = sigma, T1 = T1, payoff.profile = Call.profile, set.S = Call.set.S, K = K)
  }
}
```


```{r}
# Calculations of relative error and absolute error.
rel.errors <- (BSM.price - combinations)/BSM.price
abs.errors <- abs(BSM.price - combinations)
```

```{r}
# Tabulate the results.
df.rel <- data.frame(rel.errors)
rownames(df.rel) <- c("M = 10", "M = 100", "M = 1000", "M = 10000", "M = 100000")
colnames(df.rel) <- c("n = 10", "n = 100", "n = 1000")

df.abs <- data.frame(abs.errors)
rownames(df.abs) <- c("M = 10", "M = 100", "M = 1000", "M = 10000", "M = 100000")
colnames(df.abs) <- c("n = 10", "n = 100", "n = 1000")

knitr::kable(df.rel, caption = "Relative Errors")
knitr::kable(df.abs, caption = "Absolute Errors")
```

Interpretation of results in view of $n$ and $M$.

TESTER MED EKSEMPLER I SLIDES!

```{r, eval = F}
# slide 21 Section 3
mu <- 0.05
sigma <- 0.2
s0 <- 10
T1 <- 1
n <- 5
h <- 1/n

Z <- rnorm(n)
Z <- c(0.5377, 1.8339, -2.2588, 0.8622, 0.3188)
S.values <- rep(NA, length.out = n+1)
S.values[1] <- s0
for (j in 2:(n+1)){
  S.values[j] <- S.values[j-1] + mu*S.values[j-1]*h + sigma*S.values[j-1]*sqrt(h)*Z[j-1]
}
S.values
S.values[length(S.values)]
# Correct!
# This means that the inner loop with the Euler Method is correctly implemented at least!
```

```{r, eval = F}
MC <- function(M, n, r, s0, mu, h, sigma, T1, payoff.profile, set.S, ...){
  C.values <- rep(NA, length.out = M)
  for (i in 1:M){
    Z <- rnorm(n)
    S.values <- rep(NA, length.out = n+1)
    S.values[1] <- s0
    for (j in 2:(n+1)){
      S.values[j] <- S.values[j-1] + mu*S.values[j-1]*h + sigma*S.values[j-1]*sqrt(h)*Z[j-1]
    }
    S <- set.S(S.values) # Generality is kept using a helper function set.S.
    C.values[i] <- payoff.profile(S, K)
  }
  exp(-r*T1)*mean(C.values) # Return discounted average payoff
}
```


# Problem C - Option Pricing II

A Monte Carlo estimator is implemented for a specific Asian Call Option. This Asian Call Option averages prices every Friday. We set $n = 252$ and assume that $n = 1$ is Monday. This means that we average the prices $t_5, t_{10}, t_{15}, \ldots$. The paypff profile for this option is thus $(\bar{S}-K)^+$, where $\bar{S}$ is the arithmetic average over all the prices $t_i, \hspace{0.2em} i \in \{5, 10, 15, \ldots\}$. We set $M = 10000$ and use the parameter set $(s_0, T, r, \sigma, K) = (20, 1, 0.02, 0.24, 20)$.

```{r}
set.seed(061999)
s0 <- 20
T1 <- 1
r <- 0.02
sigma <- 0.24
K <- 20
n <- 252

# This function can be fed into the MC estimator instead. 
Asian.set.S <- function(S.values){ 
  # We extract every 5th value and calculate their arithmetic mean.
  mean(S.values[seq(5, length(S.values), 5)])
}

# Feed the payoff profile into the MC estimator. 
# This is the same as the Call.profile above, so not needed!
Asian.profile <- function(S, K){
  max(0, S-K)
}

# Still assuming that mu = r.
Asian.price <- MC(M = 10000, n = 252, r = 0.02, s0 = 20, mu = 0.02, h = 1/252, 
   sigma = 0.24, T1 = 1, Asian.profile, Asian.set.S, K = 20)
```

As we can see from the result above, the price estimated via the MC estimator is `r round(Asian.price, 2)`. THIS PRICE CAN PERHAPS BE CHECKED WITH A CALCULATOR ONLINE!

A Monte Carlo estimator is implemented for a Lookback option with payoff profile $(S_{max}-K)^+$, where $S_{max}$ refers to the maximum price during the time to maturity of the option. We use the parameter set $(s_0, T, r, \sigma, K) = (22, 2, 0.02, 0.29, 20)$ THIS K IS NOT SPECIFIED IN THE PROBLEM DESCRIPTION, BUT I WILL JUST LEAVE IT HERE NOW!

```{r}
set.seed(061999)
s0 <- 22
T1 <- 2
r <- 0.02
sigma <- 0.29
K <- 20
n <- 1000
M1 <- 1000
M2 <- 10000
M3 <- 100000

# This function can be fed into the MC estimator instead. 
lookback.set.S <- function(S.values){ 
  # We return the maximum value among the S.values. 
  max(S.values)
}

# Feed the payoff profile into the MC estimator. 
# This is the same as the Call.profile above, so not needed!
lookback.profile <- function(S, K){
  max(0, S-K)
}

# Still assuming that mu = r.
lookback.price <- MC(M = M2, n = n, r = s0, s0 = s0, mu = r, h = 1/M2, 
   sigma = sigma, T1 = T1, lookback.profile, lookback.set.S, K = 20)
```

As we can see from the result above, the price estimated via the MC estimator is `r round(lookback.price, 2)`. THIS PRICE CAN PERHAPS BE CHECKED WITH A CALCULATOR ONLINE!

```{r}
# We calculate CIs of this option price for the different values of M.

```

